<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />

    <title>Change Data Capture (CDC) - MySQL</title>
    <meta name="HandheldFriendly" content="True" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />

    <link rel="preload" href="../assets/css/app.css%3Fv=ce4b11c978.css" as="style" />
    <link rel="preload" href="../assets/js/manifest.js%3Fv=ce4b11c978" as="script" />
    <link rel="preload" href="../assets/js/vendor/content-api.min.js%3Fv=ce4b11c978" as="script" />
    <link rel="preload" href="../assets/js/vendor.js%3Fv=ce4b11c978" as="script" />
    <link rel="preload" href="../assets/js/app.js%3Fv=ce4b11c978" as="script" />

      <link rel="preload" href="../assets/css/post.css%3Fv=ce4b11c978.css" as="style" />
  <link rel="preload" href="../assets/js/post.js%3Fv=ce4b11c978" as="script" />


    <style>
      /* These font-faces are here to make fonts work if the Ghost instance is installed in a subdirectory */

      /* source-sans-pro-regular */
      @font-face {
        font-family: 'Source Sans Pro';
        font-style: normal;
        font-weight: 400;
        font-display: swap;
        src: local('SourceSansPro-Regular'),
            url("../assets/fonts/source-sans-pro/latin/source-sans-pro-regular.woff2%3Fv=ce4b11c978") format('woff2'),
            url("../assets/fonts/source-sans-pro/latin/source-sans-pro-regular.woff%3Fv=ce4b11c978") format('woff');
      }

      /* source-sans-pro-600 */
      @font-face {
        font-family: 'Source Sans Pro';
        font-style: normal;
        font-weight: 600;
        font-display: swap;
        src: local('SourceSansPro-SemiBold'),
            url("../assets/fonts/source-sans-pro/latin/source-sans-pro-600.woff2%3Fv=ce4b11c978") format('woff2'),
            url("../assets/fonts/source-sans-pro/latin/source-sans-pro-600.woff%3Fv=ce4b11c978") format('woff');
      }

      /* source-sans-pro-700 */
      @font-face {
        font-family: 'Source Sans Pro';
        font-style: normal;
        font-weight: 700;
        font-display: swap;
        src: local('SourceSansPro-Bold'),
            url("../assets/fonts/source-sans-pro/latin/source-sans-pro-700.woff2%3Fv=ce4b11c978") format('woff2'),
            url("../assets/fonts/source-sans-pro/latin/source-sans-pro-700.woff%3Fv=ce4b11c978") format('woff');
      }

      /* iconmoon */
      @font-face {
        font-family: 'icomoon';
        font-weight: normal;
        font-style: normal;
        font-display: swap;
        src: url("../assets/fonts/icomoon/icomoon.eot%3F101fc3%3Fv=ce4b11c978");
        src: url("../assets/fonts/icomoon/icomoon.eot%3F101fc3%3Fv=ce4b11c978") format('embedded-opentype'),
        url("../assets/fonts/icomoon/icomoon.ttf%3F101fc3%3Fv=ce4b11c978") format('truetype'),
        url("../assets/fonts/icomoon/icomoon.woff%3F101fc3%3Fv=ce4b11c978") format('woff'),
        url("../assets/fonts/icomoon/icomoon.svg%3F101fc3%3Fv=ce4b11c978") format('svg');
      }
    </style>

    <link rel="stylesheet" type="text/css" href="../assets/css/app.css%3Fv=ce4b11c978.css" media="screen" />

      <link rel="stylesheet" type="text/css" href="../assets/css/post.css%3Fv=ce4b11c978.css" media="screen" />


    

    <link rel="canonical" href="index.html" />
    <meta name="referrer" content="no-referrer-when-downgrade" />
    
    <meta property="og:site_name" content="Anantha Raju C" />
    <meta property="og:type" content="article" />
    <meta property="og:title" content="Change Data Capture (CDC) - MySQL" />
    <meta property="og:description" content="Introduction


Change Data Capture (CDC) is a powerful process that tracks and captures changes made to data in a database, delivering those changes in real-time to downstream processes or systems. This capability is crucial for maintaining data consistency across distributed systems, enabling real-time analytics, and more.


In this post, we" />
    <meta property="og:url" content="http://localhost:2368/change-data-capture-cdc-mysql/" />
    <meta property="og:image" content="https://images.unsplash.com/photo-1440288736878-766bd5839edb?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;MnwxMTc3M3wwfDF8c2VhcmNofDN8fGNhdGNofGVufDB8fHx8MTY2NjYxMjk1OA&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;2000" />
    <meta property="article:published_time" content="2022-10-24T12:08:33.000Z" />
    <meta property="article:modified_time" content="2024-06-15T20:14:40.000Z" />
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="Change Data Capture (CDC) - MySQL" />
    <meta name="twitter:description" content="Introduction


Change Data Capture (CDC) is a powerful process that tracks and captures changes made to data in a database, delivering those changes in real-time to downstream processes or systems. This capability is crucial for maintaining data consistency across distributed systems, enabling real-time analytics, and more.


In this post, we" />
    <meta name="twitter:url" content="http://localhost:2368/change-data-capture-cdc-mysql/" />
    <meta name="twitter:image" content="https://images.unsplash.com/photo-1440288736878-766bd5839edb?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;MnwxMTc3M3wwfDF8c2VhcmNofDN8fGNhdGNofGVufDB8fHx8MTY2NjYxMjk1OA&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;2000" />
    <meta name="twitter:label1" content="Written by" />
    <meta name="twitter:data1" content="Anantha Raju C" />
    <meta name="twitter:site" content="@anantharajuc" />
    <meta name="twitter:creator" content="@anantharajuc" />
    <meta property="og:image:width" content="2000" />
    <meta property="og:image:height" content="1329" />
    
    <script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Article",
    "publisher": {
        "@type": "Organization",
        "name": "Anantha Raju C",
        "url": "http://localhost:2368/",
        "logo": {
            "@type": "ImageObject",
            "url": "http://localhost:2368/favicon.ico",
            "width": 48,
            "height": 48
        }
    },
    "author": {
        "@type": "Person",
        "name": "Anantha Raju C",
        "image": {
            "@type": "ImageObject",
            "url": "//www.gravatar.com/avatar/a9dba06822d9729750154dfe5bf5c073?s=250&d=mm&r=x",
            "width": 250,
            "height": 250
        },
        "url": "http://localhost:2368/author/anantha/",
        "sameAs": [
            "https://anantharajuc.github.io/",
            "https://twitter.com/anantharajuc"
        ]
    },
    "headline": "Change Data Capture (CDC) - MySQL",
    "url": "http://localhost:2368/change-data-capture-cdc-mysql/",
    "datePublished": "2022-10-24T12:08:33.000Z",
    "dateModified": "2024-06-15T20:14:40.000Z",
    "image": {
        "@type": "ImageObject",
        "url": "https://images.unsplash.com/photo-1440288736878-766bd5839edb?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDN8fGNhdGNofGVufDB8fHx8MTY2NjYxMjk1OA&ixlib=rb-4.0.3&q=80&w=2000",
        "width": 2000,
        "height": 1329
    },
    "description": "Introduction\n\n\nChange Data Capture (CDC) is a powerful process that tracks and captures changes made to data in a database, delivering those changes in real-time to downstream processes or systems. This capability is crucial for maintaining data consistency across distributed systems, enabling real-time analytics, and more.\n\n\nIn this post, we will briefly document the process of setting up CDC with MySQL using various tools such as Docker, Kafka, and Debezium.\n\n\n\nMinimum Software Requirements\n\n\n",
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "http://localhost:2368/"
    }
}
    </script>

    <meta name="generator" content="Ghost 5.8" />
    <link rel="alternate" type="application/rss+xml" title="Anantha Raju C" href="../rss/index.html" />
    
    <script defer src="https://cdn.jsdelivr.net/npm/@tryghost/sodo-search@~1.1/umd/sodo-search.min.js" data-key="bd0f620eace0890d104223392c" data-styles="https://cdn.jsdelivr.net/npm/@tryghost/sodo-search@~1.1/umd/main.css" data-sodo-search="http://localhost:2368/" crossorigin="anonymous"></script>
    <script defer src="../public/cards.min.js%3Fv=ce4b11c978"></script>
    <link rel="stylesheet" type="text/css" href="../public/cards.min.css%3Fv=ce4b11c978.css">
    <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-88776389-2"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-88776389-2');
</script>
<style>:root {--ghost-accent-color: #FF1A75;}</style>

    <style>
      :root {
        --primary-subtle-color: var(--ghost-accent-color) !important;
      }
    </style>

    <script>
      // @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&dn=expat.txt Expat
      const ghostHost = "http://localhost:2368"
      // @license-end
    </script>

  </head>
  <body class="post-template">
    



  
<header class="m-header with-picture js-header">
  <div class="m-mobile-topbar" data-aos="fade-down">
    <button class="m-icon-button in-mobile-topbar js-open-menu" aria-label="Open menu">
      <span class="icon-menu" aria-hidden="true"></span>
    </button>
      <a href="../index.html" class="m-site-name in-mobile-topbar">
        Anantha Raju C
      </a>
    <button class="m-icon-button in-mobile-topbar js-open-search" aria-label="Open search">
      <span class="icon-search" aria-hidden="true"></span>
    </button>
  </div>

  <div class="m-menu js-menu">
    <button class="m-icon-button outlined as-close-menu js-close-menu" aria-label="Close menu">
      <span class="icon-close"></span>
    </button>
    <div class="m-menu__main" data-aos="fade-down">
      <div class="l-wrapper">
        <div class="m-nav js-main-nav">
          <nav class="m-nav__left js-main-nav-left" role="navigation" aria-label="Main menu">
            <ul>
                <li class="only-desktop">
                  <a href="../index.html" class="m-site-name in-desktop-menu">
                    Anantha Raju C
                  </a>
                </li>
                
    <li class="nav-about">
      <a href="../about/index.html">About</a>
    </li>
    <li class="nav-author">
      <a href="../author/anantha/index.html">Author</a>
    </li>
    <li class="nav-tags">
      <a href="../tags/index.html">Tags</a>
    </li>

              <li class="submenu-option js-submenu-option">
                <button class="m-icon-button in-menu-main more js-toggle-submenu" aria-label="Open submenu">
                  <span class="icon-more" aria-hidden="true"></span>
                </button>
                <div class="m-submenu js-submenu">
                  <div class="l-wrapper in-submenu">
                    <section class="m-recent-articles">
                      <h3 class="m-submenu-title in-recent-articles">Recent articles</h3>
                          <div class="swiper js-recent-slider">
                            <div class="swiper-wrapper">
                                <div class="swiper-slide">
                                  <a href="../building-a-real-time-data-pipeline-using-python-mysql-kafka-and-clickhouse/index.html" class="m-recent-article">
                                    <div class="m-recent-article__picture ">
                                        <img src="https://images.unsplash.com/photo-1593583845845-7d67ede93328?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;M3wxMTc3M3wwfDF8c2VhcmNofDQ4fHxwaXBlbGluZXxlbnwwfHx8fDE3MTc5MDQxNDd8MA&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;300" loading="lazy" alt="">
                                    </div>
                                    <h3 class="m-recent-article__title js-recent-article-title" title="Building a Real-Time Data Pipeline Using Python, MySQL, Kafka, and ClickHouse">
                                      Building a Real-Time Data Pipeline Using Python, MySQL, Kafka, and ClickHouse
                                    </h3>
                                    <span class="m-recent-article__date">7 days ago</span>
                                  </a>
                                </div>
                                <div class="swiper-slide">
                                  <a href="../dbt-core/index.html" class="m-recent-article">
                                    <div class="m-recent-article__picture ">
                                        <img src="https://images.unsplash.com/photo-1591164811435-2b8a547039de?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;M3wxMTc3M3wwfDF8c2VhcmNofDEyfHx0cmFuc2Zvcm1lcnN8ZW58MHx8fHwxNzAzNDkwNDYxfDA&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;300" loading="lazy" alt="">
                                    </div>
                                    <h3 class="m-recent-article__title js-recent-article-title" title="Unlocking Data Transformation Magic with dbt-core, ClickHouse, and Dagster">
                                      Unlocking Data Transformation Magic with dbt-core, ClickHouse, and Dagster
                                    </h3>
                                    <span class="m-recent-article__date">6 months ago</span>
                                  </a>
                                </div>
                                <div class="swiper-slide">
                                  <a href="../replicate-mysql-database-in-clickhouse-using/index.html" class="m-recent-article">
                                    <div class="m-recent-article__picture ">
                                        <img src="https://images.unsplash.com/photo-1472017053394-b29fded587cd?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;M3wxMTc3M3wwfDF8c2VhcmNofDI4fHx0d2lufGVufDB8fHx8MTcwMzQ4OTU2N3ww&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;300" loading="lazy" alt="">
                                    </div>
                                    <h3 class="m-recent-article__title js-recent-article-title" title="Replicate MySQL database in ClickHouse with [experimental] MaterializedMySQL Database Engine">
                                      Replicate MySQL database in ClickHouse with [experimental] MaterializedMySQL Database Engine
                                    </h3>
                                    <span class="m-recent-article__date">6 months ago</span>
                                  </a>
                                </div>
                                <div class="swiper-slide">
                                  <a href="../clickhouse/index.html" class="m-recent-article">
                                    <div class="m-recent-article__picture ">
                                        <img src="https://images.unsplash.com/photo-1542274368-443d694d79aa?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;M3wxMTc3M3wwfDF8c2VhcmNofDh8fHZlcnRpY2FsJTIwcGlwZXN8ZW58MHx8fHwxNjk5ODgxODgzfDA&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;300" loading="lazy" alt="">
                                    </div>
                                    <h3 class="m-recent-article__title js-recent-article-title" title="ClickHouse">
                                      ClickHouse
                                    </h3>
                                    <span class="m-recent-article__date">7 months ago</span>
                                  </a>
                                </div>
                            </div>
                          </div>
                    </section>
                    <section class="m-tags">
                      <h3 class="m-submenu-title">Tags</h3>
                        <ul>
                            <li>
                              <a href="../tag/aws/index.html">AWS</a>
                            </li>
                            <li>
                              <a href="../tag/apache-kafka/index.html">Apache Kafka</a>
                            </li>
                            <li>
                              <a href="../tag/apache-maven/index.html">Apache Maven</a>
                            </li>
                            <li>
                              <a href="../tag/ci-cd/index.html">CI/CD</a>
                            </li>
                            <li>
                              <a href="../tag/cli/index.html">CLI</a>
                            </li>
                            <li>
                              <a href="../tag/change-data-capture/index.html">Change Data Capture</a>
                            </li>
                            <li>
                              <a href="../tag/clickhouse/index.html">ClickHouse</a>
                            </li>
                            <li>
                              <a href="../tag/dagster/index.html">Dagster</a>
                            </li>
                            <li>
                              <a href="../tag/data/index.html">Data</a>
                            </li>
                            <li>
                              <a href="../tag/database/index.html">Database</a>
                            </li>
                        </ul>
                    </section>
                  </div>
                </div>
              </li>
            </ul>
          </nav>
          <div class="m-nav__right">
            <button class="m-icon-button in-menu-main js-open-search" aria-label="Open search">
              <span class="icon-search" aria-hidden="true"></span>
            </button>
            <div class="m-toggle-darkmode js-tooltip" data-tippy-content="Toggle light/dark mode" tabindex="0">
              <label for="toggle-darkmode" class="sr-only">
                Toggle light/dark mode
              </label>
              <input id="toggle-darkmode" type="checkbox" class="js-toggle-darkmode">
              <div>
                <span class="icon-moon moon" aria-hidden="true"></span>
                <span class="icon-sunny sun" aria-hidden="true"></span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>

</header>

<main class="main-wrap">
    
  <section class="m-hero with-picture" data-aos="fade">
    <div class="m-hero__picture in-post">
      <img
        srcset="
          https://images.unsplash.com/photo-1440288736878-766bd5839edb?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;MnwxMTc3M3wwfDF8c2VhcmNofDN8fGNhdGNofGVufDB8fHx8MTY2NjYxMjk1OA&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;300 300w,
          https://images.unsplash.com/photo-1440288736878-766bd5839edb?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;MnwxMTc3M3wwfDF8c2VhcmNofDN8fGNhdGNofGVufDB8fHx8MTY2NjYxMjk1OA&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;600 600w,
          https://images.unsplash.com/photo-1440288736878-766bd5839edb?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;MnwxMTc3M3wwfDF8c2VhcmNofDN8fGNhdGNofGVufDB8fHx8MTY2NjYxMjk1OA&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;1000 1000w,
          https://images.unsplash.com/photo-1440288736878-766bd5839edb?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;MnwxMTc3M3wwfDF8c2VhcmNofDN8fGNhdGNofGVufDB8fHx8MTY2NjYxMjk1OA&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;2000 2000w
        "
        sizes="(max-width: 600px) 600px, (max-width: 1000px) 1000px, 2000px"
        src="https://images.unsplash.com/photo-1440288736878-766bd5839edb?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;MnwxMTc3M3wwfDF8c2VhcmNofDN8fGNhdGNofGVufDB8fHx8MTY2NjYxMjk1OA&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;1000"
        alt=""
      />
    </div>
    </section>
        <div class="l-wrapper in-caption">
          <p class="m-small-text align-center">
            Photo by <a href="https://unsplash.com/@leorivas?utm_source=ghost&utm_medium=referral&utm_campaign=api-credit">Leo Rivas</a> / <a href="https://unsplash.com/?utm_source=ghost&utm_medium=referral&utm_campaign=api-credit">Unsplash</a>
          </p>
        </div>
  
  <article>
    <div class="l-content in-post">
        <div class="l-wrapper in-post  js-aos-wrapper" data-aos="fade-up"
          data-aos-delay="300">
          <div
            class="l-post-content js-progress-content">
            <header class="m-heading">
              <h1 class="m-heading__title in-post">Change Data Capture (CDC) - MySQL</h1>
              <div class="m-heading__meta">
                <span class="m-heading__meta__time">Oct 24, 2022</span>
              </div>
            </header>
            <div class="pos-relative js-post-content">
              <div class="m-share">
                <div class="m-share__content js-sticky">
                  <a href="https://www.facebook.com/sharer/sharer.php?u=http://localhost:2368/change-data-capture-cdc-mysql/"
                    class="m-icon-button filled in-share" target="_blank" rel="noopener" aria-label="Facebook">
                    <span class="icon-facebook" aria-hidden="true"></span>
                  </a>
                  <a href="https://twitter.com/intent/tweet?text=Change%20Data%20Capture%20(CDC)%20-%20MySQL&url=http://localhost:2368/change-data-capture-cdc-mysql/"
                    class="m-icon-button filled in-share" target="_blank" rel="noopener" aria-label="Twitter">
                    <span class="icon-twitter" aria-hidden="true"></span>
                  </a>
                  <button class="m-icon-button filled in-share progress js-scrolltop" aria-label="Scroll to top">
                    <span class="icon-arrow-top" aria-hidden="true"></span>
                    <svg aria-hidden="true">
                      <circle class="progress-ring__circle js-progress" fill="transparent" r="0" />
                    </svg>
                  </button>
                </div>
              </div>
              <!--kg-card-begin: markdown--><h3 id="introduction">Introduction</h3>
<p>Change Data Capture (CDC) is a powerful process that tracks and captures changes made to data in a database, delivering those changes in real-time to downstream processes or systems. This capability is crucial for maintaining data consistency across distributed systems, enabling real-time analytics, and more.</p>
<p>In this post, we will briefly document the process of setting up CDC with MySQL using various tools such as Docker, Kafka, and Debezium.</p>
<h3 id="minimum-software-requirements">Minimum Software Requirements</h3>
<p>Before we get started, ensure you have the following software installed on your machine:</p>
<ul>
<li><a href="https://www.docker.com/">Docker</a>: Used to containerize applications (MySQL, Zookeeper, Kafka, Debezium, schema-registry, kafka-ui, ksqldb-server, ksqldb-cli)</li>
<li><a href="https://docs.docker.com/compose/">Docker Compose</a>: A tool for defining and running multi-container Docker applications.</li>
<li><a href="https://www.mysql.com/">MySQL</a> Database: : The relational database management system.</li>
<li><a href="https://www.mysql.com/products/workbench/">MySQL Workbench</a>: Or on any other MySQL database client/console.</li>
</ul>
<h3 id="mysql-configuration-mysqlcnf">MySQL Configuration (<code>mysql.cnf</code>)</h3>
<p>To enable CDC on your MySQL database, you need to configure the MySQL server appropriately. Here’s an example of what your mysql.cnf file should look like:</p>
<pre><code class="language-txt">[mysqld]
server-id         = 223344
log_bin           = mysql-bin
expire_logs_days  = 1
binlog_format     = row
</code></pre>
<ul>
<li><code>server-id</code>: A unique identifier for the server.</li>
<li><code>log_bin</code>: Enables binary logging.</li>
<li><code>expire_logs_days</code>: Specifies the number of days to retain binary logs.</li>
<li><code>binlog_format</code>: Sets the binary log format to 'row', which is necessary for CDC.</li>
</ul>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h3 id="sample-project-setup">Sample Project Setup</h3>
<p>Follow these steps to set up the CDC environment</p>
<p><strong>1. Clone the repository</strong></p>
<p>First, clone the repository containing the project setup:</p>
<pre><code class="language-shell">git clone https://github.com/AnanthaRajuC/Streaming_ETL_pipeline_MySQL.git
cd Streaming_ETL_pipeline_MySQL
</code></pre>
<h3 id="running-the-application-via-docker-compose">Running the application via docker compose</h3>
<p><strong>2. Pull all required docker images</strong></p>
<p>Pull all the necessary Docker images defined in the Docker Compose file:</p>
<pre><code class="language-shell">docker compose -f docker-compose.yaml pull
</code></pre>
<p><strong>3. Start up the environment</strong></p>
<p>Start the Docker containers. The first time you do this, the images will be downloaded from the remote server, which may take some time:</p>
<pre><code class="language-shell">docker compose -f docker-compose.yaml up
</code></pre>
<p>You should see output indicating that various services are being created and started:</p>
<pre><code class="language-shell">Creating network &quot;streaming_etl_pipeline_mysql_webproxy&quot; with driver &quot;bridge&quot;
Creating zookeeper ... done
Creating kafka     ... done
Creating debezium           ... done
Creating cp-schema-registry ... done
Creating kafka-connect-01   ... done
Creating ksqldb-server      ... done
Creating ksqldb-cli         ... done
</code></pre>
<p><strong>4. Accessing Kafka Topics via Kakfka-UI</strong></p>
<p>Optionally, start <a href="https://github.com/provectus/kafka-ui">Kafka UI</a>, an open-source web UI for Apache Kafka Management</p>
<pre><code class="language-shell">docker run --name=kafka-ui --network=streaming_etl_pipeline_mysql_webproxy -p 8080:8080 -e KAFKA_CLUSTERS_0_NAME=local -e KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka:9092 -d provectuslabs/kafka-ui:latest
</code></pre>
<p>Access the Kafka-UI console at: <strong><a href="http://localhost:8080">http://localhost:8080</a></strong></p>
<p><img src="https://raw.githubusercontent.com/AnanthaRajuC/Streaming_ETL_pipeline_MySQL/main/documentation/images/04-kafka-topics-before-debezium.png" alt="Kafka UI" loading="lazy"></p>
<p><strong>5. Verify Everything is Running</strong></p>
<p>Ensure all containers are up and running:</p>
<pre><code class="language-shell">docker ps
</code></pre>
<p><img src="https://raw.githubusercontent.com/AnanthaRajuC/Streaming_ETL_pipeline_MySQL/main/documentation/images/09-docker-ps.png" alt="Docker Compose Up" loading="lazy"></p>
<p><strong>IMPORTANT:</strong> If any components do not show &quot;Up&quot; under the <code>Status</code> column (e.g., they say &quot;Exit&quot;) then you must rectify this before continuing. As a first solution, try re-issuing the <code>docker-compose up -d</code> command.</p>
<p><strong>6. Access ksqlDB via ksqlDB-CLI</strong></p>
<p>Launch the KSQL CLI in another terminal window.</p>
<pre><code class="language-shell">docker exec -it ksqldb-cli ksql http://ksqldb-server:8088
</code></pre>
<p><img src="https://raw.githubusercontent.com/AnanthaRajuC/Streaming_ETL_pipeline_MySQL/main/documentation/images/10-ksql-db-initial.png" alt="ksqlDB CLI" loading="lazy"></p>
<h4 id="tear-down-the-stack">Tear down the stack</h4>
<p>To stop and remove the containers, run:</p>
<pre><code class="language-shell">docker stop kafka-ui
</code></pre>
<pre><code class="language-shell">docker rm kafka-ui
</code></pre>
<p>Then, bring down the rest of the environment:</p>
<pre><code class="language-shell">docker compose -f docker-compose.yaml down
</code></pre>
<p>You should see output indicating that the containers are being stopped and removed:</p>
<pre><code class="language-shell">Stopping ksqldb-cli       ... done
Stopping ksqldb-server    ... done
Stopping kafka-connect-01 ... done
Stopping debezium         ... done
Stopping kafka            ... done
Stopping zookeeper        ... done
Removing ksqldb-cli         ... done
Removing ksqldb-server      ... done
Removing kafka-connect-01   ... done
Removing cp-schema-registry ... done
Removing debezium           ... done
Removing kafka              ... done
Removing zookeeper          ... done
Removing network streaming_etl_pipeline_mysql_webproxy
</code></pre>
<p><em>If you want to preserve the state of all containers, run <code>docker-compose stop</code> instead.</em></p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h4 id="initial-mysql-preparation">Initial MySQL preparation</h4>
<p>To get started with our MySQL database, we'll set up the initial schema, tables, and populate them with sample data. This preparation is crucial for ensuring that our database is ready for further development and integration.</p>
<h4 id="mysql">MySQL</h4>
<p><strong>1. Declare schema, user and permissions.</strong></p>
<p>First, create a new schema and user, then grant the necessary permissions to the user.</p>
<pre><code class="language-sql">-- create schema
CREATE SCHEMA streaming_etl_db;

-- use schema
USE streaming_etl_db;

-- Create user 
CREATE USER 'debezium' IDENTIFIED WITH mysql_native_password BY 'Debezium@123#';

-- Grant privileges to user
GRANT SELECT, RELOAD, SHOW DATABASES, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 'debezium';

-- Reload the grant tables in the mysql database enabling the changes to take effect without reloading or restarting mysql service
FLUSH PRIVILEGES;
</code></pre>
<p><strong>2. Create Tables</strong></p>
<p>Next, create the tables for storing geographical data, addresses, and personal information. Each table includes fields and constraints tailored to the data it will store.</p>
<pre><code class="language-sql">-- Table for geographical data
CREATE TABLE `geo` (
  `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT 'Unique ID for each entry.',
  `uuid` VARCHAR(50) DEFAULT (uuid()),
  `created_date_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT 'Field representing the date the entity containing the field was created.',
  `last_modified_date_time` datetime DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP ,
  `lat` varchar(255) DEFAULT NULL,
  `lng` varchar(255) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8mb4 COMMENT='Application Log.';
</code></pre>
<pre><code class="language-sql">-- Table for addresses
CREATE TABLE `address` (
  `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT 'Unique ID for each entry.',
  `uuid` VARCHAR(50) DEFAULT (uuid()),
  `created_date_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT 'Field representing the date the entity containing the field was created.',
  `last_modified_date_time` datetime DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP ,
  `city` varchar(255) DEFAULT NULL,
  `zipcode` varchar(255) DEFAULT NULL,
  `state` varchar(255) DEFAULT NULL,
  `geo_id` bigint(20) DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `FK_geo_id` (`geo_id`),
  CONSTRAINT `FKC_geo_id` FOREIGN KEY (`geo_id`) REFERENCES `geo` (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;
</code></pre>
<pre><code class="language-sql">-- Table for personal information
CREATE TABLE `person` (
  `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT 'Unique ID for each entry.',
  `uuid` VARCHAR(50) DEFAULT (uuid()),
  `created_date_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT 'Field representing the date the entity containing the field was created.',
  `last_modified_date_time` datetime DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP ,
  `first_name` varchar(255) NOT NULL,
  `last_name` varchar(255) DEFAULT NULL,
  `email` varchar(255) DEFAULT NULL,
  `gender` varchar(255) DEFAULT NULL,
  `registration` datetime DEFAULT NULL,
  `age` int DEFAULT NULL,
  `address_id` bigint(20) DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `FK_address_id` (`address_id`),
  CONSTRAINT `FKC_address_id` FOREIGN KEY (`address_id`) REFERENCES `address` (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;
</code></pre>
<p><strong>3. Insert Sample Data</strong></p>
<p>Populate the tables with some sample data to verify the structure and relationships.</p>
<pre><code class="language-sql">-- Insert sample data into geo table
INSERT INTO `streaming_etl_db`.`geo`(`lat`,`lng`)VALUES('la14','lo14');

-- Insert sample data into address table
INSERT INTO `streaming_etl_db`.`address`(`city`,`zipcode`,`state`,`geo_id`)VALUES('c14','z14','s14',1);

-- Insert sample data into person table
INSERT INTO `streaming_etl_db`.`person`(`first_name`,`last_name`,`email`,`gender`,`registration`,`age`,`address_id`)VALUES('fn14','ln14','example@domain.com','M',now(),34,1);
</code></pre>
<p><strong>4. Select Statements</strong></p>
<p>Retrieve data from the tables to ensure everything is set up correctly.</p>
<pre><code class="language-sql">-- Join query to retrieve data from person, address, and geo tables
SELECT * 
FROM streaming_etl_db.person p
LEFT JOIN streaming_etl_db.address a on a.id = p.address_id
LEFT JOIN streaming_etl_db.geo g on g.id = a.geo_id;
</code></pre>
<pre><code class="language-sql">-- Select all data from person table
SELECT * FROM streaming_etl_db.person;

-- Select all data from address table
SELECT * FROM streaming_etl_db.address;
</code></pre>
<p>By following these steps, you will have a fully prepared MySQL database with the necessary schema, tables, and sample data. This setup will serve as a foundation for further development and data integration.</p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h3 id="debezium-registration">Debezium Registration</h3>
<p>In this section, we'll set up and register the Debezium connector to monitor changes in our MySQL database and stream them to Kafka. Debezium is an open-source distributed platform for change data capture (CDC).</p>
<p><strong>Registering the Debezium Connector</strong></p>
<p>To register the Debezium connector, use the following curl command.</p>
<pre><code class="language-shell">curl -i -X POST -H &quot;Accept:application/json&quot; -H &quot;Content-Type:application/json&quot; 127.0.0.1:8083/connectors/ -d '{
  &quot;name&quot;: &quot;streaming_ETL_pipeline_MySQL-connector&quot;,
  &quot;config&quot;: {
    &quot;connector.class&quot;: &quot;io.debezium.connector.mysql.MySqlConnector&quot;,
    &quot;database.hostname&quot;: &quot;172.17.0.1&quot;,
    &quot;database.port&quot;: &quot;3306&quot;,
    &quot;database.user&quot;: &quot;debezium&quot;,
    &quot;database.password&quot;: &quot;Debezium@123#&quot;,
    &quot;database.server.name&quot;: &quot;mysql&quot;,
	  &quot;database.server.id&quot;: &quot;223344&quot;,
    &quot;database.include.list&quot;: &quot;streaming_etl_db&quot;,
	  &quot;database.allowPublicKeyRetrieval&quot;: true,
	  &quot;database.history.kafka.bootstrap.servers&quot;: &quot;kafka:9092&quot;,
	  &quot;database.history.kafka.topic&quot;: &quot;mysql-streaming_etl_db-person&quot;,
	  &quot;time.precision.mode&quot;: &quot;connect&quot;,
    &quot;include.schema.changes&quot;: false,
    &quot;transforms&quot;: &quot;unwrap,dropTopicPrefix&quot;,
	  &quot;transforms.unwrap.type&quot;: &quot;io.debezium.transforms.ExtractNewRecordState&quot;,
	  &quot;transforms.dropTopicPrefix.type&quot;:&quot;org.apache.kafka.connect.transforms.RegexRouter&quot;,
	  &quot;transforms.dropTopicPrefix.regex&quot;:&quot;asgard.demo.(.*)&quot;,
	  &quot;transforms.dropTopicPrefix.replacement&quot;:&quot;$1&quot;,
	  &quot;key.converter&quot;:&quot;org.apache.kafka.connect.json.JsonConverter&quot;,
	  &quot;key.converter.schemas.enable&quot;: &quot;false&quot;,
	  &quot;value.converter&quot;:&quot;org.apache.kafka.connect.json.JsonConverter&quot;,
	  &quot;value.converter.schemas.enable&quot;: &quot;false&quot;
  }
}'
</code></pre>
<p>This command will:</p>
<ul>
<li>Create a new connector named streaming_ETL_pipeline_MySQL-connector.</li>
<li>Configure it to monitor the streaming_etl_db schema on the MySQL instance.</li>
<li>Stream the change data to a Kafka topic named mysql-streaming_etl_db-person.</li>
</ul>
<p><img src="https://raw.githubusercontent.com/AnanthaRajuC/Streaming_ETL_pipeline_MySQL/main/documentation/images/01-debezium-registration.png" alt="debezium-registration" loading="lazy"></p>
<p>After registering the Debezium connector, you can check the status and information of the connectors.</p>
<p><strong>Checking Connector Status</strong><br>
To verify the status of the connectors, visit:</p>
<p><a href="http://localhost:8083/connectors?expand=info&amp;expand=status">http://localhost:8083/connectors?expand=info&amp;expand=status</a></p>
<p><img src="https://raw.githubusercontent.com/AnanthaRajuC/Streaming_ETL_pipeline_MySQL/main/documentation/images/02-debezium-connectors.png" alt="connectors" loading="lazy"></p>
<p>To check the status of the specific Debezium connector, visit:</p>
<p><a href="http://localhost:8083/connectors/streaming_ETL_pipeline_MySQL-connector/status">http://localhost:8083/connectors/streaming_ETL_pipeline_MySQL-connector/status</a></p>
<p><img src="https://raw.githubusercontent.com/AnanthaRajuC/Streaming_ETL_pipeline_MySQL/main/documentation/images/03-debezium-connector-status.png" alt="connector-status" loading="lazy"></p>
<p><strong>Kafka UI</strong></p>
<p>You can also use the Kafka UI to inspect the topics and messages being streamed. Visit the Kafka UI at:</p>
<p><a href="http://localhost:8080">http://localhost:8080</a></p>
<p><img src="https://raw.githubusercontent.com/AnanthaRajuC/Streaming_ETL_pipeline_MySQL/main/documentation/images/05-kafka-topics-after-registration.png" alt="Kafka UI after Debezium Registration" loading="lazy"></p>
<p><strong>Viewing the Person Topic</strong></p>
<p>Finally, check the messages in the person topic to ensure data is being streamed correctly:</p>
<p><img src="https://raw.githubusercontent.com/AnanthaRajuC/Streaming_ETL_pipeline_MySQL/main/documentation/images/06-kafka-topic-message.png" alt="Person Topic" loading="lazy"></p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h3 id="accessing-ksqldb-via-ksqldb-cli">Accessing ksqlDb via ksqldb-cli</h3>
<p>In this section, we will explore how to access and use ksqlDB via the ksqlDB-CLI to interact with Kafka topics, create streams, perform stream-stream joins, and finally, sink the enriched stream back to MySQL.</p>
<p><strong>Checking Topics, Streams, and Tables</strong><br>
Start by checking the available topics, streams, and tables in ksqlDB.</p>
<pre><code class="language-sql">-- Display available topics
SHOW TOPICS;

-- Display available streams
SHOW STREAMS;

-- Display available tables
SHOW TABLES;
</code></pre>
<p><strong>Declaring Streams</strong><br>
To begin processing data, declare the necessary streams. Set the offset to the earliest to ensure you capture all existing messages.</p>
<pre><code class="language-sql">-- Set offset to the earliest
SET 'auto.offset.reset' = 'earliest';
</code></pre>
<p>Create streams to capture data from the Kafka topics corresponding to the MySQL tables.</p>
<pre><code class="language-sql">-- Create stream for the person topic
CREATE STREAM PERSON_STREAM (
  id BIGINT,
  uuid VARCHAR,
  created_date_time TIMESTAMP,
  last_modified_date_time TIMESTAMP,
  name VARCHAR,
  username VARCHAR,
  address_id BIGINT
) WITH (KAFKA_TOPIC='mysql.streaming_etl_db.person', VALUE_FORMAT='JSON');
</code></pre>
<pre><code class="language-sql">-- Create stream for the address topic
CREATE STREAM ADDRESS_STREAM (
  id BIGINT,
  uuid VARCHAR,
  created_date_time TIMESTAMP,
  last_modified_date_time TIMESTAMP,
  city VARCHAR,
  street VARCHAR,
  suite VARCHAR,
  zipcode VARCHAR,
  geo_id BIGINT
) WITH (KAFKA_TOPIC='mysql.streaming_etl_db.address', VALUE_FORMAT='JSON');
</code></pre>
<p><strong>Querying Streams</strong><br>
Retrieve data from the streams to ensure they are correctly set up.</p>
<pre><code class="language-sql">-- Select a single record from the PERSON_STREAM
SELECT * FROM PERSON_STREAM EMIT CHANGES LIMIT 1;
</code></pre>
<pre><code class="language-sql">+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+
|ID                       |UUID                     |CREATED_DATE_TIME        |LAST_MODIFIED_DATE_TIME  |NAME                     |USERNAME                 |ADDRESS_ID               |
+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+
|1                        |ce8d2120-1f93-11ed-8647-0|2022-08-19T13:22:00.000  |2022-08-19T13:22:00.000  |d14                      |dbz14                    |1                        |
|                         |c9a3cfadc50              |                         |                         |                         |                         |                         |
Limit Reached
Query terminated
</code></pre>
<p>Describe the stream to get details about its schema.</p>
<pre><code class="language-sql">-- Describe the PERSON_STREAM
DESCRIBE PERSON_STREAM;

-- Select all records from PERSON_STREAM
SELECT * FROM PERSON_STREAM;
</code></pre>
<p><strong>Stream-Stream Join</strong><br>
Perform a join between the <code>PERSON_STREAM</code> and <code>ADDRESS_STREAM</code> to create an enriched stream combining data from both.</p>
<pre><code class="language-sql">-- Create an enriched stream by joining PERSON_STREAM and ADDRESS_STREAM
CREATE STREAM PERSON_ADDRESS_ENRICHED_STREAM WITH (
FORMAT='JSON', 
KAFKA_TOPIC='person_address_enriched', 
PARTITIONS=1, 
REPLICAS=1
) AS 
SELECT
  P.ID P_ID,
  A.ID A_ID,
  P.NAME NAME,
  A.CITY CITY
FROM PERSON_STREAM P
LEFT OUTER JOIN ADDRESS_STREAM A WITHIN 1 HOURS GRACE PERIOD 30 MINUTES 
ON ((A.ID = P.ADDRESS_ID))
EMIT CHANGES;
</code></pre>
<h4 id="kafka-sink-mysql-db">Kafka Sink MySQL DB</h4>
<p>Finally, create a sink connector to write the enriched stream back to the MySQL database.</p>
<pre><code class="language-sql">-- Create a sink connector for the enriched stream
CREATE SINK CONNECTOR SINK_PERSON_ADDRESS_ENRICHED_STREAM WITH (
  'connector.class'            = 'io.confluent.connect.jdbc.JdbcSinkConnector',
  'connection.url'             = 'jdbc:mysql://172.17.0.1:3306/',
  'connection.user'            = 'debezium',
  'connection.password'        = 'Debezium@123#',
  'topics'                     = 'PERSON_ADDRESS_ENRICHED_STREAM',
  'key.converter'              = 'org.apache.kafka.connect.json.JsonConverter',
  'key.converter.schemas.enable' = 'false',
  'value.converter'            = 'org.apache.kafka.connect.json.JsonConverter',
  'value.converter.schemas.enable' = 'false'
);
</code></pre>
<p>By following these steps, you can access ksqlDB via the ksqlDB-CLI, create and query streams, perform joins, and sink the enriched data back to MySQL.</p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h3 id="accessing-ksqldb-via-ksqldb-cli">Accessing ksqlDb via ksqldb-cli</h3>
<p>In this section, we'll delve into how to access ksqlDB using the ksqlDB-CLI, focusing on creating and querying tables, and performing joins.</p>
<p><strong>Checking Topics, Streams, and Tables</strong><br>
Start by listing the available topics, streams, and tables in your ksqlDB environment to ensure you have everything set up correctly.</p>
<pre><code class="language-sql">-- Display available topics
SHOW TOPICS;

-- Display available streams
SHOW STREAMS;

-- Display available tables
SHOW TABLES;
</code></pre>
<p><strong>Declaring Tables</strong><br>
Next, declare tables to represent your Kafka topics in ksqlDB. These tables will enable you to perform SQL-like queries on streaming data.</p>
<pre><code class="language-sql">-- Create table for the person topic
CREATE TABLE PERSON (
  id BIGINT PRIMARY KEY,
  uuid VARCHAR,
  created_date_time TIMESTAMP,
  last_modified_date_time TIMESTAMP,
  name VARCHAR,
  username VARCHAR,
  address_id BIGINT
) WITH (KAFKA_TOPIC='mysql.streaming_etl_db.person', VALUE_FORMAT='JSON');

-- Create table for the address topic
CREATE TABLE ADDRESS (
  id BIGINT PRIMARY KEY,
  uuid VARCHAR,
  created_date_time TIMESTAMP,
  last_modified_date_time TIMESTAMP,
  city VARCHAR,
  street VARCHAR,
  suite VARCHAR,
  zipcode VARCHAR,
  geo_id BIGINT
) WITH (KAFKA_TOPIC='mysql.streaming_etl_db.address', VALUE_FORMAT='JSON');
</code></pre>
<p><strong>Querying Tables</strong><br>
Retrieve data from the tables to verify that they are correctly set up and ingesting data from the corresponding Kafka topics.</p>
<pre><code class="language-sql">-- Select a single record from the PERSON table
SELECT * FROM PERSON EMIT CHANGES LIMIT 1;

-- Select a single record from the ADDRESS table
SELECT * FROM ADDRESS EMIT CHANGES LIMIT 1;
</code></pre>
<p><strong>Performing Joins</strong><br>
Join the <strong>PERSON</strong> and <strong>ADDRESS</strong> tables to enrich the data, combining fields from both tables based on a common key.</p>
<pre><code class="language-sql">-- Perform a left join between PERSON and ADDRESS tables
SELECT 
  P.NAME,
  A.CITY
FROM PERSON P
LEFT JOIN ADDRESS A 
ON A.id = P.address_id
EMIT CHANGES 
LIMIT 1;
</code></pre>
<pre><code class="language-sql">-- Perform an inner join between PERSON and ADDRESS tables
SELECT 
  P.NAME, 
  A.CITY
FROM PERSON P
INNER JOIN ADDRESS A
ON A.id = P.address_id
EMIT CHANGES
LIMIT 1;
</code></pre>
<p><strong>Creating Enriched Table</strong><br>
Create a new table to store the results of the join, providing a persistent view of the enriched data.</p>
<pre><code class="language-sql">-- Create a table for the enriched person and address data
CREATE TABLE PERSON_ADDRESS_ENRICHED (
  P_ID BIGINT,
  A_ID BIGINT,
  NAME VARCHAR,
  CITY VARCHAR
) WITH (KAFKA_TOPIC='person_address_enriched', VALUE_FORMAT='JSON');
</code></pre>
<p><strong>Managing Tables</strong><br>
You can also manage your tables by dropping them when they are no longer needed.</p>
<pre><code class="language-sql">-- Drop the PERSON table if it exists
DROP TABLE IF EXISTS PERSON;
</code></pre>
<p>By following these steps, you can effectively use ksqlDB to create and manage tables, perform joins, and enrich your streaming data, enabling powerful real-time data processing capabilities in your ETL pipeline.</p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h3 id="conclusion">Conclusion</h3>
<p>In this tutorial, we walked through the process of setting up a streaming ETL pipeline using MySQL, Debezium, Kafka, and ksqlDB. We began by preparing our MySQL database with the necessary schema, tables, and sample data. Then, we registered the Debezium connector to monitor changes and stream them to Kafka. Using ksqlDB, we created and queried streams and tables, performed joins to enrich our data, and finally, sank the enriched data back into MySQL.</p>
<p>By leveraging these powerful tools, you can build robust and scalable real-time data processing pipelines that enable you to respond to changes in your data as they happen. This setup provides a foundation for more complex stream processing tasks and opens up possibilities for real-time analytics, monitoring, and more.</p>
<!--kg-card-end: markdown-->
            </div>
          </div>
        </div>
        <section class="m-author">
          <div class="m-author__content">
            <div class="m-author__picture">
              <a href="../author/anantha/index.html" class="m-author-picture" aria-label="Anantha Raju C">
                  <div style="background-image: url(http://www.gravatar.com/avatar/a9dba06822d9729750154dfe5bf5c073?s&);"></div>
              </a>
            </div>
            <div class="m-author__info">
              <h4 class="m-author__name">
                <a href="../author/anantha/index.html">Anantha Raju C</a>
              </h4>
                <p class="m-author__bio">| Poetry | Music | Cinema | Books | Visual Art | Software Engineering |</p>
              <ul class="m-author-links">
                  <li>
                    <a href="https://anantharajuc.github.io/" target="_blank" rel="noopener" aria-label="Website">
                      <span class="icon-globe" aria-hidden="true"></span>
                    </a>
                  </li>
                  <li>
                    <a href="https://twitter.com/@anantharajuc" target="_blank" rel="noopener" aria-label="Twitter">
                      <span class="icon-twitter" aria-hidden="true"></span>
                    </a>
                  </li>
              </ul>
            </div>
          </div>
        </section>
    </div>
  </article>
</main>



    
<div class="m-search js-search" role="dialog" aria-modal="true" aria-label="Search">
  <button class="m-icon-button outlined as-close-search js-close-search" aria-label="Close search">
    <span class="icon-close" aria-hidden="true"></span>
  </button>
  <div class="m-search__content">
    <form class="m-search__form">
      <div class="pos-relative">
        <span class="icon-search m-search-icon" aria-hidden="true"></span>
        <label for="search-input" class="sr-only">
          Type to search
        </label>
        <input id="search-input" type="text" class="m-input in-search js-input-search" placeholder="Type to search">
      </div>
    </form>
    <div class="js-search-results hide"></div>
    <p class="m-not-found align-center hide js-no-results">
      No results for your search, please try with something else.
    </p>
  </div>
</div>

    
<footer class="m-footer">
  <div class="m-footer__content">
    <nav class="m-footer-social">
        <a href="https://twitter.com/anantharajuc" target="_blank" rel="noopener" aria-label="Twitter">
          <span class="icon-twitter" aria-hidden="true"></span>
        </a>
      <a href="http://localhost:2368/rss" aria-label="RSS">
        <span class="icon-rss" aria-hidden="true"></span>
      </a>
    </nav>
    <p class="m-footer-copyright">
      <span>Anantha Raju C &copy; 2024</span>
      <span>&nbsp; &bull; &nbsp;</span>
      <span>Published with <a href="https://ghost.org" target="_blank" rel="noopener">Ghost</a></span>
    </p>
    <p class="m-footer-copyright jslicense">
      <a href="../assets/html/javascript.html%3Fv=ce4b11c978.html" rel="jslicense">JavaScript license information</a>
    </p>
  </div>
</footer>

    <script defer src="../assets/js/manifest.js%3Fv=ce4b11c978"></script>
    <script defer src="../assets/js/vendor/content-api.min.js%3Fv=ce4b11c978"></script>
    <script defer src="../assets/js/vendor.js%3Fv=ce4b11c978"></script>
    <script defer src="../assets/js/app.js%3Fv=ce4b11c978"></script>

      <script defer src="../assets/js/post.js%3Fv=ce4b11c978"></script>


    
  </body>
</html>
